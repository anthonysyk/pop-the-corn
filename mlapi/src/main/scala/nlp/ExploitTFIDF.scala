package nlp

import nlp.TFIDF.Article
import org.apache.spark.SparkConf
import org.apache.spark.mllib.linalg
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.linalg.distributed._
import org.apache.spark.rdd.RDD
import org.apache.spark.sql.{SaveMode, SparkSession}


object ExploitTFIDF {

//  val conf: SparkConf = new SparkConf().setMaster("local[*]").setAppName("ExploitTFIDF")
//  val ss: SparkSession = SparkSession.builder().config(conf).getOrCreate()

  val conf: SparkConf = new SparkConf().setMaster("yarn").set("submit.deployMode", "client")
  val sparkConfs = Map(
    "rdd.compress" -> "true",
    "ui.enables" -> "true",
    "serializer" -> "org.apache.spark.serializer.KryoSerializer",
    "driver.memory" -> "12g",
    "executor.memory" -> "12g",
    "dynamicAllocation.maxExecutors" -> "110",
    "dynamicAllocation.enabled" -> "true",
    "yarn.executor.memoryOverhead" -> "4000",
    "default.parallelism" -> "128",
    "suffle.manager" -> "hash",
    "suffle.service.enabled" -> "true",
    "kryoserializer.buffer.max" -> "512m",
    "submit.deployMode" -> "client"
  )
  sparkConfs.foreach(t => conf.set("spark."+t._1, t._2))
  val ss: SparkSession = SparkSession.builder().config(conf).getOrCreate()


  case class MovieMatrix(indexId: Long, movieId: Int, scores: Map[String, Double], inputVector: Seq[Double], vector: linalg.Vector, similarities: Option[MatrixEntry] = None)

  case class MovieSimilarity(idIndex: Long, idMovie: Int, similarity: Seq[MatrixEntry])

  def main(args: Array[String]): Unit = {

    val path = getClass.getResource("/tfidf-movies").getPath
    val prodPath = "/home/usr_trafgar/test/resources"

    import ss.implicits._
    val articleRDD = ss.read.parquet(prodPath).as[Article].rdd.sortBy(_.id).persist()

    println(articleRDD.count)

    val dictionnary: Seq[String] = articleRDD.flatMap { article =>
      article.words
    }.distinct().collect().toSeq

    val scoresByMovie: RDD[MovieMatrix] = articleRDD.zipWithIndex.map {
      case (movie, index) => MovieMatrix(index, movie.id, movie.score.toMap, Nil, Vectors.dense(Array.empty[Double]))
    }

    val preCosineSimilarityMovies: RDD[MovieMatrix] = scoresByMovie.map { movieMatrix =>
      val inputVector = dictionnary.map { word =>
        movieMatrix.scores.getOrElse(word, 0.0)
      }
      val vector = Vectors.dense(inputVector.toArray)
      movieMatrix.copy(inputVector = inputVector, vector = vector)
    }

    val indexedRows: RDD[IndexedRow] = preCosineSimilarityMovies.map { movieMatrix =>
      IndexedRow(movieMatrix.indexId, movieMatrix.vector)
    }.persist

    val irm: IndexedRowMatrix = new IndexedRowMatrix(indexedRows)

    val resultMatrix: RDD[MatrixEntry] = irm.toCoordinateMatrix().transpose().toRowMatrix().columnSimilarities().entries

    resultMatrix.toDF.coalesce(1).write.mode(SaveMode.Overwrite).parquet("mlapi/src/main/resources/similarity-matrix")

    ss.close()
  }

}
